{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Repo Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Discuss idea with Professor\n",
    "# Q. What high prompt-density repositories should we be looking at? And, for which parsers?\n",
    "\n",
    "# USING DEFAULT PARSER for now\n",
    "import json\n",
    "with open('../parse_data/repo_to_prompts.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ **Spell Checker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving prompts to files so that cspell can check them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_dir = 'repos_temp'\n",
    "# Make repo_temp\n",
    "if not os.path.exists(root_dir):\n",
    "    os.makedirs(root_dir)\n",
    "    for repo in data:\n",
    "        filename = f\"{repo}.py\"\n",
    "        path = os.path.join(root_dir, filename)\n",
    "        with open(path, 'w') as f:\n",
    "            f.writelines(data[repo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run: cspell repos_temp/*.py > typos.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'836304831~langchain-anal': ['coreference',\n",
       "  'serp',\n",
       "  'serp',\n",
       "  'alava',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'k√πzu',\n",
       "  'k√πzu',\n",
       "  'sparql',\n",
       "  'sparql',\n",
       "  'sparql',\n",
       "  'sparql',\n",
       "  'foaf',\n",
       "  'foaf',\n",
       "  'foaf',\n",
       "  'sparql',\n",
       "  'foaf',\n",
       "  'foaf',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'coreference',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'documentated'],\n",
       " 'aigc-apps~LLM_Solution': ['hologres', 'faiss'],\n",
       " 'algopapi~RetroformAgent': ['glennis',\n",
       "  'maycomb',\n",
       "  'atticus',\n",
       "  'maycomb',\n",
       "  'maycomb',\n",
       "  'engelbert',\n",
       "  'gyula',\n",
       "  'g√∂mb√∂s',\n",
       "  'engelbert',\n",
       "  'gyula',\n",
       "  'g√∂mb√∂s',\n",
       "  'amilcare',\n",
       "  'mooss',\n",
       "  'beÀàniÀêto',\n",
       "  'aÀàmilkare',\n",
       "  'anÀàdr…õÀêa',\n",
       "  'mussoÀàliÀêni',\n",
       "  'avanti',\n",
       "  'popolo',\n",
       "  'italo',\n",
       "  'stresa',\n",
       "  'pietro',\n",
       "  'sasso',\n",
       "  'waffen',\n",
       "  'harald',\n",
       "  'repubblica',\n",
       "  'sociale',\n",
       "  'italiana',\n",
       "  'sal√≤',\n",
       "  'petacci',\n",
       "  'attempted',\n",
       "  'heskin',\n",
       "  'heskin',\n",
       "  'heskin',\n",
       "  'heskin',\n",
       "  'deschanel',\n",
       "  'heskin',\n",
       "  'kingsman',\n",
       "  'brooklynn',\n",
       "  'brooklynn',\n",
       "  'brooklynn',\n",
       "  'brooklynn'],\n",
       " 'americium-241~Omnitool_UI': ['exemples',\n",
       "  'formated',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'testtool',\n",
       "  'testtool',\n",
       "  'checkstate',\n",
       "  'checkstate'],\n",
       " 'Antony90~arxiv-discord': ['appopriate'],\n",
       " 'argilla-io~argilla': ['argilla',\n",
       "  'argilla',\n",
       "  'argilla',\n",
       "  'argilla',\n",
       "  'argilla',\n",
       "  'argilla',\n",
       "  'argilla',\n",
       "  'prajjwal',\n",
       "  'argilla',\n",
       "  'prajjwal',\n",
       "  'argilla',\n",
       "  'setfit',\n",
       "  'argilla',\n",
       "  'peft',\n",
       "  'prajjwal',\n",
       "  'spacy',\n",
       "  'spacy',\n",
       "  'prajjwal',\n",
       "  'sshleifer',\n",
       "  'sshleifer',\n",
       "  'sshleifer',\n",
       "  'sshleifer'],\n",
       " 'ausboss~DiscordLangAgent': ['hilar',\n",
       "  'raiden',\n",
       "  'revengeance',\n",
       "  'swingin',\n",
       "  'rockstar',\n",
       "  'eargasm',\n",
       "  'shooooot',\n",
       "  'botname'],\n",
       " 'AutoLLM~AutoAgents': ['webiste'],\n",
       " 'aws-solutions-library-samples~guidance-for-custom-search-of-an-enterprise-knowledge-base-on-aws': ['unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'acces',\n",
       "  'serp',\n",
       "  'serp',\n",
       "  'alava',\n",
       "  'documentated',\n",
       "  'coreference',\n",
       "  'acces',\n",
       "  'serp',\n",
       "  'serp',\n",
       "  'alava'],\n",
       " 'Bi-Mars~persona_builder': ['their', 'their'],\n",
       " 'ByronHsu~FlyteGPT': ['necessary'],\n",
       " 'chatchat-space~Langchain-Chatchat': ['bigdata',\n",
       "  'bigdata',\n",
       "  'weathercheck',\n",
       "  'weathercheck',\n",
       "  'numexpr',\n",
       "  'numexpr',\n",
       "  'numexpr',\n",
       "  'numexpr',\n",
       "  'numexpr'],\n",
       " 'codedog-ai~codedog': ['convienently', 'totaly', 'aboud', 'informations'],\n",
       " 'Coding-Crashkurse~LangChain-Discord-Bot': ['dicord'],\n",
       " 'Coding-Crashkurse~LangChain-Intermediate-Project': ['vectorstore'],\n",
       " 'Coding-Crashkurse~LangChain-On-Azure': ['huninchen'],\n",
       " 'DannyBoy5240~Langchain': ['unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'coreference',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'craigslist',\n",
       "  'craigslist',\n",
       "  'craigslist',\n",
       "  'newmark',\n",
       "  'newmark',\n",
       "  'newmark',\n",
       "  'royale',\n",
       "  'royale',\n",
       "  'royale',\n",
       "  'coreference',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'typesubmit',\n",
       "  'typesubmit',\n",
       "  'typesubmit',\n",
       "  'typesubmit',\n",
       "  'dorsia',\n",
       "  'typesubmit',\n",
       "  'dorsia',\n",
       "  'opentable',\n",
       "  'dorsia',\n",
       "  'dorsia'],\n",
       " 'davila7~langchain-101': ['nombre'],\n",
       " 'deepfates~npc': ['frobizz', 'frobnoid', 'frobozzle'],\n",
       " 'docker~genai-stack': ['stackoverflow',\n",
       "  'upvoted',\n",
       "  'accuate',\n",
       "  'stackoverflow'],\n",
       " 'DonGuillotine~langchain-claude-chatbot': ['ecommerce'],\n",
       " 'FredGoo~langchain-chinese-chat-models': ['ipadpro',\n",
       "  'macbook',\n",
       "  'macbook',\n",
       "  'ipadpro'],\n",
       " 'Gamma-Software~AppifyAi': ['streamlit',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'additionnaly',\n",
       "  'halucinate',\n",
       "  'streamlit',\n",
       "  'anwser',\n",
       "  'anwser',\n",
       "  'anwser',\n",
       "  'greatings',\n",
       "  'ajoute',\n",
       "  'streamlit',\n",
       "  'ajoute',\n",
       "  'ceci',\n",
       "  'rajout√©',\n",
       "  'avec',\n",
       "  'fonction',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'randn',\n",
       "  'randn'],\n",
       " 'huangjia2019~langchain': ['assitiant'],\n",
       " 'hwchase17~chat-langchain-notion': ['blendle',\n",
       "  'blendle',\n",
       "  'blendle',\n",
       "  'blendle'],\n",
       " 'hwchase17~langchain-hub': ['necessary'],\n",
       " 'ibizabroker~slack-hr-gpt': ['mrkdwn', 'mrkdwn', 'mrkdwn', 'closesly'],\n",
       " 'IntelligenzaArtificiale~Free-personal-AI-Assistant-with-plugin': ['alessandro',\n",
       "  'ciciarelli',\n",
       "  'owener',\n",
       "  'intelligenzaartificialeitalia',\n",
       "  'istruction',\n",
       "  'previus',\n",
       "  'alessandro',\n",
       "  'ciciarelli',\n",
       "  'owener',\n",
       "  'intelligenzaartificialeitalia',\n",
       "  'istruction',\n",
       "  'previus',\n",
       "  'alessandro',\n",
       "  'ciciarelli',\n",
       "  'owener',\n",
       "  'intelligenzaartificialeitalia',\n",
       "  'istruction',\n",
       "  'argumented',\n",
       "  'previus',\n",
       "  'argumented',\n",
       "  'alessandro',\n",
       "  'ciciarelli',\n",
       "  'owener',\n",
       "  'intelligenzaartificialeitalia',\n",
       "  'istruction',\n",
       "  'previus',\n",
       "  'detalied',\n",
       "  'alessandro',\n",
       "  'ciciarelli',\n",
       "  'owener',\n",
       "  'intelligenzaartificialeitalia',\n",
       "  'istruction',\n",
       "  'previus',\n",
       "  'detalied',\n",
       "  'gived',\n",
       "  'detalied',\n",
       "  'gived',\n",
       "  'detalied'],\n",
       " 'itamargol~openai': ['coldy'],\n",
       " 'jayli~langchain-GLM_Agent': ['information'],\n",
       " 'jiamingkong~RWKV_chains': ['numexpr',\n",
       "  'numexpr',\n",
       "  'numexpr',\n",
       "  'numexpr',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'succint'],\n",
       " 'jiatastic~GPTInterviewer': ['autoplay',\n",
       "  'followiing',\n",
       "  'followiing',\n",
       "  'followiing',\n",
       "  'backpropagation',\n",
       "  'requrres',\n",
       "  'knowldge',\n",
       "  'followiing'],\n",
       " 'Joentze~chad-bod': ['roleplay'],\n",
       " 'JorisdeJong123~7-Days-of-LangChain': ['transript',\n",
       "  'thaught',\n",
       "  'thaught',\n",
       "  'desiging',\n",
       "  'consice',\n",
       "  'desiging',\n",
       "  'mindmap',\n",
       "  'mindmap'],\n",
       " 'junruxiong~IncarnaMind': ['conatain', 'incarna'],\n",
       " 'kyegomez~swarms': ['seperatedly',\n",
       "  'bulletpoint',\n",
       "  'qubits',\n",
       "  'qubits',\n",
       "  'qubits',\n",
       "  'qubits',\n",
       "  'qubit',\n",
       "  'qubits',\n",
       "  'qubit',\n",
       "  'qubit',\n",
       "  'qubit',\n",
       "  'qubit',\n",
       "  'bulletpoints'],\n",
       " 'langchain-ai~langchain-benchmarks': ['dhead',\n",
       "  'exporatory',\n",
       "  'dhead',\n",
       "  'exporatory'],\n",
       " 'langchain-ai~langchain-teacher': ['iterface'],\n",
       " 'langchain-ai~langchain': ['unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'coreference',\n",
       "  'coreference',\n",
       "  'documentated',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'serp',\n",
       "  'serp',\n",
       "  'alava',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa'],\n",
       " 'LeonardoRocca-13~Project_Advertisement': ['meteo', 'address'],\n",
       " 'logspace-ai~langflow': ['langflow', 'langflow'],\n",
       " 'maanvithag~thinkai': ['philosophy'],\n",
       " 'Magic-Emerge~know-more': ['unenforceability', 'arpa', 'darpa', 'arpa'],\n",
       " 'MarkEdmondson1234~edmonbrain': ['apologise',\n",
       "  'edmonbrain',\n",
       "  'edmondson',\n",
       "  'naur',\n",
       "  'aavailable',\n",
       "  'stopstring',\n",
       "  'stopstring'],\n",
       " 'MarkEdmondson1234~langchain-github': ['separated'],\n",
       " 'mazzzystar~teach-show-consult': ['alda', 'alda', 'alda', 'alda', 'alda'],\n",
       " 'melih-unsal~DemoGPT': ['streamlit',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'streamlit',\n",
       "  'llms',\n",
       "  'streamlit',\n",
       "  'docstore',\n",
       "  'dtypes',\n",
       "  'streamlit',\n",
       "  'llms',\n",
       "  'docstore',\n",
       "  'dtypes',\n",
       "  'releated',\n",
       "  'formattable',\n",
       "  'releated',\n",
       "  'releated',\n",
       "  'dtypes'],\n",
       " 'MikeBorman1~LangchainResearchAgent': ['usless', \"doesn't\"],\n",
       " 'minkj1992~jarvis': ['interset'],\n",
       " 'neobundy~pippaGPT': ['beffiting', 'backlighting'],\n",
       " 'OpenGVLab~InternGPT': ['framewise'],\n",
       " 'paolorechia~learn-langchain': ['idendentation',\n",
       "  'ouput',\n",
       "  'ouput',\n",
       "  'ouput',\n",
       "  'ouput'],\n",
       " 'petermartens98~OpenAI-LangChain-Movie-Concept-and-DALLE2-Poster-Generation-Streamlit-Web-App': ['mookie',\n",
       "  'denzel',\n",
       "  'blac',\n",
       "  'blac',\n",
       "  'stallworth',\n",
       "  'klux',\n",
       "  'stallworth',\n",
       "  'blac',\n",
       "  'completelt',\n",
       "  'addapt',\n",
       "  'yout',\n",
       "  'resposne',\n",
       "  'tarrentino',\n",
       "  'tarrentino',\n",
       "  'desciptions',\n",
       "  'empahize',\n",
       "  'tarrantenio',\n",
       "  'hitmen',\n",
       "  'inglourious',\n",
       "  'basterds',\n",
       "  'inglourious',\n",
       "  'basterds',\n",
       "  'basterds',\n",
       "  'shosanna',\n",
       "  'm√©lanie',\n",
       "  'landa',\n",
       "  'subvers',\n",
       "  'inglourious',\n",
       "  'basterds',\n",
       "  'inglourious',\n",
       "  'basterds',\n",
       "  'landa',\n",
       "  'inglourious',\n",
       "  'reimagining',\n",
       "  'completelt',\n",
       "  'addapt',\n",
       "  'tarrentino',\n",
       "  'yout',\n",
       "  'resposne',\n",
       "  'uniquw',\n",
       "  'tenenbaums',\n",
       "  'addapt',\n",
       "  'yout',\n",
       "  'resposne'],\n",
       " 'petermartens98~OpenAI-Whisper-Audio-Transcription-And-Summarization-Chatbot': ['inacurracies',\n",
       "  'transcirpt',\n",
       "  'inacurracies',\n",
       "  'transcirpt',\n",
       "  'inacurracies',\n",
       "  'transcirpt'],\n",
       " 'Qiyuan-Ge~OpenAssistant': ['numexpr',\n",
       "  'numexpr',\n",
       "  'numexpr',\n",
       "  'numexpr',\n",
       "  'begain'],\n",
       " 'rajib76~langchain_examples': ['rdeb',\n",
       "  'excerpts',\n",
       "  'comversation',\n",
       "  'ancsa',\n",
       "  'ameri'],\n",
       " 'Ravi-Teja-konda~OSGPT': ['compreply',\n",
       "  'compopt',\n",
       "  'compreply',\n",
       "  'compopt',\n",
       "  'compreply',\n",
       "  'nosort',\n",
       "  'compdef',\n",
       "  'descr',\n",
       "  'descr',\n",
       "  'descr',\n",
       "  'compadd',\n",
       "  'loadautofunc',\n",
       "  'autoload',\n",
       "  'compdef'],\n",
       " 'retr0reg~Ret2GPT': ['analysising',\n",
       "  'pwntools',\n",
       "  'recvuntil',\n",
       "  'sendline',\n",
       "  'recvuntil',\n",
       "  'sendline',\n",
       "  'explanation',\n",
       "  'pwntools',\n",
       "  'decompiled',\n",
       "  'respones',\n",
       "  'respone',\n",
       "  'decompiled',\n",
       "  'information',\n",
       "  'analysising',\n",
       "  'pwntools',\n",
       "  'argument',\n",
       "  'exploition',\n",
       "  'deletenote',\n",
       "  'recvuntil',\n",
       "  'sendline',\n",
       "  'recvuntil',\n",
       "  'sendline'],\n",
       " 'Safakan~TalkWithYourFiles': ['behaviour'],\n",
       " 'Saik0s~DevAssistant': ['reask'],\n",
       " 'Saik0s~SwiftDocAutomator': ['subrange', 'xdigit'],\n",
       " 'saqib772~Prompt-Engineering-LangChain': ['shoud', 'desription'],\n",
       " 'Sayvai-io~custom-tools': ['getdate',\n",
       "  'curdate',\n",
       "  'curdate',\n",
       "  'sysdate',\n",
       "  'clic'],\n",
       " 'sejaldua~inquizitive': ['abonia', 'sojasingarayar'],\n",
       " 'showlab~VLog': ['connet', 'chatbox'],\n",
       " 'sivasurend~langchain_utilities': ['flashdrives',\n",
       "  'doordash',\n",
       "  'webflow',\n",
       "  'robinhood'],\n",
       " 'TechNickAI~AICodeBot': ['aicodebot', 'seplling', 'seplling'],\n",
       " 'the-crypt-keeper~can-ai-code': ['corectness'],\n",
       " 'thissayantan~gpt-pdf': ['endoftext'],\n",
       " 'TOBB-ETU-CS-Community~TOBB-GPT': ['g√∂revde',\n",
       "  'yapman',\n",
       "  'gereken',\n",
       "  'kullanƒ±cƒ±',\n",
       "  'sorularƒ±nƒ±',\n",
       "  'arama',\n",
       "  'sorgularƒ±na',\n",
       "  'd√∂n√º≈üt√ºrmektir',\n",
       "  'kullanƒ±cƒ±',\n",
       "  'soru',\n",
       "  'sorduƒüunda',\n",
       "  'soruyu',\n",
       "  'kullanƒ±cƒ±nƒ±n',\n",
       "  'bilmek',\n",
       "  'istediƒüi',\n",
       "  'bilgileri',\n",
       "  'getirecek',\n",
       "  'arama',\n",
       "  'sorgusuna',\n",
       "  'd√∂n√º≈üt√ºrmelisin',\n",
       "  'soru',\n",
       "  'fiil',\n",
       "  'i√ßeriyorsa',\n",
       "  'fiili',\n",
       "  'kaldƒ±rarak',\n",
       "  'isime',\n",
       "  'd√∂n√º≈üt√ºrmen',\n",
       "  'gerekiyor',\n",
       "  'eƒüer',\n",
       "  'soru',\n",
       "  't√ºrk√ße',\n",
       "  't√ºrk√ße',\n",
       "  'ingilizce',\n",
       "  'ingilizce',\n",
       "  'cevap',\n",
       "  '√ºret',\n",
       "  'cevabƒ±',\n",
       "  'formatƒ±nda',\n",
       "  'd√∂nd√ºr',\n",
       "  'formatƒ±',\n",
       "  '≈ü√∂yle',\n",
       "  'olmalƒ±',\n",
       "  'd√∂n√º≈üt√ºrmen',\n",
       "  'gereken',\n",
       "  'soru',\n",
       "  'tƒ±rnak',\n",
       "  'i≈üaretleri',\n",
       "  'arasƒ±ndadƒ±r',\n",
       "  'verdiƒüin',\n",
       "  'cevap',\n",
       "  'yalnƒ±zca',\n",
       "  'arama',\n",
       "  'sorgusu',\n",
       "  'almalƒ±',\n",
       "  'ba≈üka',\n",
       "  'herhangi',\n",
       "  'yazmamalƒ±',\n",
       "  'tƒ±rnak',\n",
       "  'i≈üareti',\n",
       "  'gibi',\n",
       "  'noktalama',\n",
       "  'i≈üareti',\n",
       "  'eklememelisin',\n",
       "  'sonucu',\n",
       "  'formatƒ±nda',\n",
       "  'd√∂nmelisin',\n",
       "  'formatƒ±',\n",
       "  '≈ü√∂yle',\n",
       "  'olmalƒ±'],\n",
       " 'Tom-A-Roberts~LangQuest': ['singleplayer',\n",
       "  'prioritising',\n",
       "  'summarised',\n",
       "  'artstation'],\n",
       " 'topoteretes~PromethAI-Backend': ['inluding', 'recomendation', 'subgoal'],\n",
       " 'Umi7899~langchain-ChatGLM-My': ['information'],\n",
       " 'Undertone0809~promptulate': ['duckduckgo',\n",
       "  'numexpr',\n",
       "  'numexpr',\n",
       "  'numexpr',\n",
       "  'numexpr'],\n",
       " 'vishwasg217~finsight': ['atleast'],\n",
       " 'voxel51~voxelgpt': ['fiftyone',\n",
       "  'mistakenness',\n",
       "  'fiftyone',\n",
       "  'mistakenness',\n",
       "  'fiftyone',\n",
       "  'fiftyone',\n",
       "  'fiftyone',\n",
       "  'mistakenness',\n",
       "  'mistakenness',\n",
       "  'mistakenness',\n",
       "  'segmentations'],\n",
       " 'wordweb~langchain-ChatGLM-and-TigerBot': ['information'],\n",
       " 'xusenlinzy~api-for-open-llm': ['mutiple', 'mutiple', 'intp'],\n",
       " 'yujiosaka~ChatIQ': ['mrkdwn'],\n",
       " 'zaldivards~ContextQA': ['wheather',\n",
       "  'wheather',\n",
       "  'wheater',\n",
       "  'whather',\n",
       "  'wheater',\n",
       "  'obervation'],\n",
       " 'zapier~langchain-nla-util': ['coreference',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'arpa',\n",
       "  'unenforceability',\n",
       "  'arpa',\n",
       "  'darpa',\n",
       "  'typesubmit',\n",
       "  'typesubmit',\n",
       "  'typesubmit',\n",
       "  'typesubmit',\n",
       "  'dorsia',\n",
       "  'typesubmit',\n",
       "  'dorsia',\n",
       "  'opentable',\n",
       "  'dorsia',\n",
       "  'dorsia'],\n",
       " 'zilliztech~akcio': ['akcio', 'akcio', 'akcio', 'akcio', 'akcio']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_typos = {}\n",
    "custom_dict = set([\"langchain\", \"langchain's\", \"zelenskyy\", \"dataframe\", \"summarise\", \"huggingface\"])\n",
    "\n",
    "# Read typos.txt into memory\n",
    "with open('typos.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        repo = line[0]\n",
    "        typo = line[-1][1:-1].lower()\n",
    "\n",
    "        # Skip if typo is in custom dict\n",
    "        if typo in custom_dict:\n",
    "            continue\n",
    "\n",
    "        # extract repo name\n",
    "        repo = repo.split('/')[-1].split(':')[0][:-3]\n",
    "\n",
    "        # Add typo to dict\n",
    "        if repo not in repo_typos:\n",
    "            repo_typos[repo] = []\n",
    "        repo_typos[repo].append(typo)\n",
    "\n",
    "repo_typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'arpa': 26,\n",
       "         'streamlit': 21,\n",
       "         'numexpr': 17,\n",
       "         'unenforceability': 15,\n",
       "         'darpa': 15,\n",
       "         'argilla': 10,\n",
       "         'typesubmit': 10,\n",
       "         'coreference': 8,\n",
       "         'serp': 8,\n",
       "         'dorsia': 8,\n",
       "         'sparql': 5,\n",
       "         'foaf': 5,\n",
       "         'heskin': 5,\n",
       "         'alessandro': 5,\n",
       "         'ciciarelli': 5,\n",
       "         'owener': 5,\n",
       "         'intelligenzaartificialeitalia': 5,\n",
       "         'istruction': 5,\n",
       "         'previus': 5,\n",
       "         'qubits': 5,\n",
       "         'qubit': 5,\n",
       "         'alda': 5,\n",
       "         'inglourious': 5,\n",
       "         'basterds': 5,\n",
       "         'fiftyone': 5,\n",
       "         'mistakenness': 5,\n",
       "         'akcio': 5,\n",
       "         'alava': 4,\n",
       "         'brooklynn': 4,\n",
       "         'prajjwal': 4,\n",
       "         'sshleifer': 4,\n",
       "         'blendle': 4,\n",
       "         'mrkdwn': 4,\n",
       "         'detalied': 4,\n",
       "         'information': 4,\n",
       "         'followiing': 4,\n",
       "         'ouput': 4,\n",
       "         'recvuntil': 4,\n",
       "         'sendline': 4,\n",
       "         'soru': 4,\n",
       "         'documentated': 3,\n",
       "         'maycomb': 3,\n",
       "         'craigslist': 3,\n",
       "         'newmark': 3,\n",
       "         'royale': 3,\n",
       "         'anwser': 3,\n",
       "         'dtypes': 3,\n",
       "         'releated': 3,\n",
       "         'blac': 3,\n",
       "         'addapt': 3,\n",
       "         'yout': 3,\n",
       "         'resposne': 3,\n",
       "         'tarrentino': 3,\n",
       "         'inacurracies': 3,\n",
       "         'transcirpt': 3,\n",
       "         'compreply': 3,\n",
       "         'descr': 3,\n",
       "         'pwntools': 3,\n",
       "         'arama': 3,\n",
       "         'k√πzu': 2,\n",
       "         'engelbert': 2,\n",
       "         'gyula': 2,\n",
       "         'g√∂mb√∂s': 2,\n",
       "         'testtool': 2,\n",
       "         'checkstate': 2,\n",
       "         'spacy': 2,\n",
       "         'acces': 2,\n",
       "         'their': 2,\n",
       "         'necessary': 2,\n",
       "         'bigdata': 2,\n",
       "         'weathercheck': 2,\n",
       "         'opentable': 2,\n",
       "         'stackoverflow': 2,\n",
       "         'ipadpro': 2,\n",
       "         'macbook': 2,\n",
       "         'ajoute': 2,\n",
       "         'randn': 2,\n",
       "         'argumented': 2,\n",
       "         'gived': 2,\n",
       "         'thaught': 2,\n",
       "         'desiging': 2,\n",
       "         'mindmap': 2,\n",
       "         'dhead': 2,\n",
       "         'exporatory': 2,\n",
       "         'langflow': 2,\n",
       "         'stopstring': 2,\n",
       "         'llms': 2,\n",
       "         'docstore': 2,\n",
       "         'stallworth': 2,\n",
       "         'completelt': 2,\n",
       "         'landa': 2,\n",
       "         'compopt': 2,\n",
       "         'compdef': 2,\n",
       "         'analysising': 2,\n",
       "         'decompiled': 2,\n",
       "         'curdate': 2,\n",
       "         'seplling': 2,\n",
       "         'gereken': 2,\n",
       "         'kullanƒ±cƒ±': 2,\n",
       "         'd√∂n√º≈üt√ºrmen': 2,\n",
       "         't√ºrk√ße': 2,\n",
       "         'ingilizce': 2,\n",
       "         'cevap': 2,\n",
       "         'formatƒ±nda': 2,\n",
       "         'formatƒ±': 2,\n",
       "         '≈ü√∂yle': 2,\n",
       "         'olmalƒ±': 2,\n",
       "         'tƒ±rnak': 2,\n",
       "         'i≈üareti': 2,\n",
       "         'mutiple': 2,\n",
       "         'wheather': 2,\n",
       "         'wheater': 2,\n",
       "         'hologres': 1,\n",
       "         'faiss': 1,\n",
       "         'glennis': 1,\n",
       "         'atticus': 1,\n",
       "         'amilcare': 1,\n",
       "         'mooss': 1,\n",
       "         'beÀàniÀêto': 1,\n",
       "         'aÀàmilkare': 1,\n",
       "         'anÀàdr…õÀêa': 1,\n",
       "         'mussoÀàliÀêni': 1,\n",
       "         'avanti': 1,\n",
       "         'popolo': 1,\n",
       "         'italo': 1,\n",
       "         'stresa': 1,\n",
       "         'pietro': 1,\n",
       "         'sasso': 1,\n",
       "         'waffen': 1,\n",
       "         'harald': 1,\n",
       "         'repubblica': 1,\n",
       "         'sociale': 1,\n",
       "         'italiana': 1,\n",
       "         'sal√≤': 1,\n",
       "         'petacci': 1,\n",
       "         'attempted': 1,\n",
       "         'deschanel': 1,\n",
       "         'kingsman': 1,\n",
       "         'exemples': 1,\n",
       "         'formated': 1,\n",
       "         'appopriate': 1,\n",
       "         'setfit': 1,\n",
       "         'peft': 1,\n",
       "         'hilar': 1,\n",
       "         'raiden': 1,\n",
       "         'revengeance': 1,\n",
       "         'swingin': 1,\n",
       "         'rockstar': 1,\n",
       "         'eargasm': 1,\n",
       "         'shooooot': 1,\n",
       "         'botname': 1,\n",
       "         'webiste': 1,\n",
       "         'convienently': 1,\n",
       "         'totaly': 1,\n",
       "         'aboud': 1,\n",
       "         'informations': 1,\n",
       "         'dicord': 1,\n",
       "         'vectorstore': 1,\n",
       "         'huninchen': 1,\n",
       "         'nombre': 1,\n",
       "         'frobizz': 1,\n",
       "         'frobnoid': 1,\n",
       "         'frobozzle': 1,\n",
       "         'upvoted': 1,\n",
       "         'accuate': 1,\n",
       "         'ecommerce': 1,\n",
       "         'additionnaly': 1,\n",
       "         'halucinate': 1,\n",
       "         'greatings': 1,\n",
       "         'ceci': 1,\n",
       "         'rajout√©': 1,\n",
       "         'avec': 1,\n",
       "         'fonction': 1,\n",
       "         'assitiant': 1,\n",
       "         'closesly': 1,\n",
       "         'coldy': 1,\n",
       "         'succint': 1,\n",
       "         'autoplay': 1,\n",
       "         'backpropagation': 1,\n",
       "         'requrres': 1,\n",
       "         'knowldge': 1,\n",
       "         'roleplay': 1,\n",
       "         'transript': 1,\n",
       "         'consice': 1,\n",
       "         'conatain': 1,\n",
       "         'incarna': 1,\n",
       "         'seperatedly': 1,\n",
       "         'bulletpoint': 1,\n",
       "         'bulletpoints': 1,\n",
       "         'iterface': 1,\n",
       "         'meteo': 1,\n",
       "         'address': 1,\n",
       "         'philosophy': 1,\n",
       "         'apologise': 1,\n",
       "         'edmonbrain': 1,\n",
       "         'edmondson': 1,\n",
       "         'naur': 1,\n",
       "         'aavailable': 1,\n",
       "         'separated': 1,\n",
       "         'formattable': 1,\n",
       "         'usless': 1,\n",
       "         \"doesn't\": 1,\n",
       "         'interset': 1,\n",
       "         'beffiting': 1,\n",
       "         'backlighting': 1,\n",
       "         'framewise': 1,\n",
       "         'idendentation': 1,\n",
       "         'mookie': 1,\n",
       "         'denzel': 1,\n",
       "         'klux': 1,\n",
       "         'desciptions': 1,\n",
       "         'empahize': 1,\n",
       "         'tarrantenio': 1,\n",
       "         'hitmen': 1,\n",
       "         'shosanna': 1,\n",
       "         'm√©lanie': 1,\n",
       "         'subvers': 1,\n",
       "         'reimagining': 1,\n",
       "         'uniquw': 1,\n",
       "         'tenenbaums': 1,\n",
       "         'begain': 1,\n",
       "         'rdeb': 1,\n",
       "         'excerpts': 1,\n",
       "         'comversation': 1,\n",
       "         'ancsa': 1,\n",
       "         'ameri': 1,\n",
       "         'nosort': 1,\n",
       "         'compadd': 1,\n",
       "         'loadautofunc': 1,\n",
       "         'autoload': 1,\n",
       "         'explanation': 1,\n",
       "         'respones': 1,\n",
       "         'respone': 1,\n",
       "         'argument': 1,\n",
       "         'exploition': 1,\n",
       "         'deletenote': 1,\n",
       "         'behaviour': 1,\n",
       "         'reask': 1,\n",
       "         'subrange': 1,\n",
       "         'xdigit': 1,\n",
       "         'shoud': 1,\n",
       "         'desription': 1,\n",
       "         'getdate': 1,\n",
       "         'sysdate': 1,\n",
       "         'clic': 1,\n",
       "         'abonia': 1,\n",
       "         'sojasingarayar': 1,\n",
       "         'connet': 1,\n",
       "         'chatbox': 1,\n",
       "         'flashdrives': 1,\n",
       "         'doordash': 1,\n",
       "         'webflow': 1,\n",
       "         'robinhood': 1,\n",
       "         'aicodebot': 1,\n",
       "         'corectness': 1,\n",
       "         'endoftext': 1,\n",
       "         'g√∂revde': 1,\n",
       "         'yapman': 1,\n",
       "         'sorularƒ±nƒ±': 1,\n",
       "         'sorgularƒ±na': 1,\n",
       "         'd√∂n√º≈üt√ºrmektir': 1,\n",
       "         'sorduƒüunda': 1,\n",
       "         'soruyu': 1,\n",
       "         'kullanƒ±cƒ±nƒ±n': 1,\n",
       "         'bilmek': 1,\n",
       "         'istediƒüi': 1,\n",
       "         'bilgileri': 1,\n",
       "         'getirecek': 1,\n",
       "         'sorgusuna': 1,\n",
       "         'd√∂n√º≈üt√ºrmelisin': 1,\n",
       "         'fiil': 1,\n",
       "         'i√ßeriyorsa': 1,\n",
       "         'fiili': 1,\n",
       "         'kaldƒ±rarak': 1,\n",
       "         'isime': 1,\n",
       "         'gerekiyor': 1,\n",
       "         'eƒüer': 1,\n",
       "         '√ºret': 1,\n",
       "         'cevabƒ±': 1,\n",
       "         'd√∂nd√ºr': 1,\n",
       "         'i≈üaretleri': 1,\n",
       "         'arasƒ±ndadƒ±r': 1,\n",
       "         'verdiƒüin': 1,\n",
       "         'yalnƒ±zca': 1,\n",
       "         'sorgusu': 1,\n",
       "         'almalƒ±': 1,\n",
       "         'ba≈üka': 1,\n",
       "         'herhangi': 1,\n",
       "         'yazmamalƒ±': 1,\n",
       "         'gibi': 1,\n",
       "         'noktalama': 1,\n",
       "         'eklememelisin': 1,\n",
       "         'sonucu': 1,\n",
       "         'd√∂nmelisin': 1,\n",
       "         'singleplayer': 1,\n",
       "         'prioritising': 1,\n",
       "         'summarised': 1,\n",
       "         'artstation': 1,\n",
       "         'inluding': 1,\n",
       "         'recomendation': 1,\n",
       "         'subgoal': 1,\n",
       "         'duckduckgo': 1,\n",
       "         'atleast': 1,\n",
       "         'segmentations': 1,\n",
       "         'intp': 1,\n",
       "         'whather': 1,\n",
       "         'obervation': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All typos frequency\n",
    "all_typos = []\n",
    "for repo in repo_typos:\n",
    "    all_typos.extend(repo_typos[repo])\n",
    "\n",
    "# Get frequency of each typo\n",
    "from collections import Counter\n",
    "typos_freq = Counter(all_typos)\n",
    "typos_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get typo freq for each repo\n",
    "repo_typos_freq = {}\n",
    "for repo in repo_typos:\n",
    "    repo_typos_freq[repo] = {}\n",
    "    for typo in repo_typos[repo]:\n",
    "        if typo not in repo_typos_freq[repo]:\n",
    "            repo_typos_freq[repo][typo] = 0\n",
    "        repo_typos_freq[repo][typo] += 1\n",
    "\n",
    "with open('repo_typos_freq.json', 'w') as f:\n",
    "    json.dump(repo_typos_freq, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7fdaae204dc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Get text\n",
    "text = \"\"\n",
    "for repo in repo_typos:\n",
    "    text = text + \" \".join(repo_typos[repo]) + \" \"\n",
    "\n",
    "# Create a word cloud object\n",
    "wc = WordCloud()\n",
    "\n",
    "# Generate the word cloud\n",
    "wc.generate(text)\n",
    "\n",
    "# Save the word cloud\n",
    "wc.to_file(\"repo_typos_cloud.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßµ **Detecting String Interpolation with lack of spacing** (STOPPED WORKING ON THIS)\n",
    "\n",
    "it makes a big difference in tokenization: without the space the `>{` and `}</` are single tokens\n",
    "\n",
    "Reference:\n",
    "- https://twitter.com/bio_bootloader/status/1728192365897351225\n",
    "- https://twitter.com/abacaj/status/1728190808191537604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# repo_withoutSpacing = {}\n",
    "\n",
    "# for repo in data:\n",
    "#     repo_withoutSpacing[repo] = re.findall(r'([^\\s$]\\{+\\s*.*?\\s*\\}+[^\\s$])', \" \".join(data[repo]))\n",
    "\n",
    "# with open('repo_withoutSpacing.json', 'w') as f:\n",
    "#     json.dump(repo_withoutSpacing, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

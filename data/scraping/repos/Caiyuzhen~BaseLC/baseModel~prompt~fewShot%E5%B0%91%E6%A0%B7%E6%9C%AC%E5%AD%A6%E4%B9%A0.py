from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.prompts.few_shot import FewShotPromptTemplate


"""
	å°‘æ ·æœ¬å­¦ä¹ 
		å°‘æ ·æœ¬å­¦ä¹ ä¸ä¼šæ”¹å˜æ¨¡å‹çš„ç»“æ„ï¼Œè€Œæ˜¯æ”¹å˜æ¨¡å‹çš„å‚æ•°ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿé€‚åº”æ–°çš„ä»»åŠ¡
 		å°‘æ ·æœ¬å­¦ä¹ çš„ç›®æ ‡æ˜¯åœ¨å°‘é‡æ ·æœ¬çš„æƒ…å†µä¸‹ï¼Œè®©æ¨¡å‹å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›
"""

EXAMPLES = [
	{
		"question": "ä½ å¥½å—?",
		"answer": "å½“ç„¶!æˆ‘å¾ˆå¥½!"
	},
 	{
 		"question": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?",
		"answer": "å½“ç„¶!å¤©æ°”å¾ˆä¸é”™!"
	},
  	{
 		"question": "ä»Šå¤©çš„é£Ÿç‰©æ€ä¹ˆæ ·?",
		"answer": "å½“ç„¶!é£Ÿç‰©å¾ˆç¾å‘³!"
	},
]


def get_user_input():
	input_content = input("è¯·è¾“å…¥é—®é¢˜: ")
	return input_content


def run_llm(input_content):
    llm = OpenAI()
    
    example_prompt = PromptTemplate(
		input_variables=["question", "answer"],
		template="Question: {question}\n{answer}" # ğŸ”¥ç›¸å½“äºåˆ©ç”¨ä¸Šé¢ EXAMPLES çš„æ•°æ®è¿›è¡Œæ ¼å¼åŒ–
	)
    
    prompt = FewShotPromptTemplate(
		examples = EXAMPLES,
		example_prompt = example_prompt,
		suffix="Question: {input}", # ğŸ”¥ ä»¥ {input} ä½œä¸ºé—®é¢˜çš„è¾“å…¥
		input_variables=["input"]
	)

    chain = LLMChain(llm=llm, prompt=prompt)
    res = chain.run(input_content) # ğŸŒŸæ”¾å…¥ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
    return res


if __name__ == "__main__":
    input_content = get_user_input()
    result = run_llm(input_content)
    print(result)

from langchain import PromptTemplate, LLMChain
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
import telebot
from utils import get_environment_variable, download_telegram_file
from utils.conversation_utils import conversate, end_conversation

import openai


START_COMMANDS = ["start", "hi"]
END_COMMANDS = ["end", "bye"]
BOT_TOKEN = get_environment_variable("BOT_TOKEN")
OPENAI_API_KEY = get_environment_variable("OPENAI_API_KEY")

conversations = {}
prompts = {} 

bot = telebot.TeleBot(BOT_TOKEN)


def transcribe_audio_with_openai(audio_filepath, model="whisper-1"):
    with open(audio_filepath, "rb") as audio_file:
        transcript = openai.Audio.transcribe(model, audio_file)
    return transcript.to_dict()["text"]


def process_text_with_custom_instructions(text: str, instructions: str) -> str:
    """
    Summarize a given text using a language model.

    Args:
        text (str): The text to be summarized.
        user_context (str): Additional context to be provided to the language model.

    Returns:
        str: The summarized text generated by the language model.
    """

    user_context = f"{instructions}. Ejecuta las instrucciones anteriores sobre este texto: {{text}}. Lo que hagas, limÃ­tate Ãºnicamente a hacerlo sobre el texto. Answer:"

    prompt = PromptTemplate(template=user_context, input_variables=['text'])

    model_name = "gpt-3.5-turbo"
    model = ChatOpenAI(model_name=model_name)

    llm_chain = LLMChain(prompt=prompt, llm=model)

    return llm_chain.run(text)


@bot.message_handler(commands=START_COMMANDS)
def send_welcome(message: telebot.types.Message):
    """
    Respond to the '/start' and '/hi' commands with a welcome message.

    Args:
        message (telebot.types.Message): The message object representing the user's command.
    """
    if len(message.text.split(" ")) > 1:
        system_prompt = message.text.split(" ", 1)[1]
        prompts[message.chat.id] = system_prompt
    welcome_message = "Hola, si has llegado hasta aquÃ­ es que ya soy un bot sÃºper inteligente... Â¡Ahora ademÃ¡s puedo entender tus audios! ğŸ¤¯. EnvÃ­ame un mensaje"
    bot.reply_to(message, welcome_message)


@bot.message_handler(commands=END_COMMANDS)
def send_goodbye(message: telebot.types.Message):
    """
    Respond to the '/end' and '/bye' commands with a welcome message.

    Args:
        message (telebot.types.Message): The message object representing the user's command.
    """
    user_id = message.chat.id
    end_conversation(user_id, conversations)
    goodbye_message = "Chao, espero que la Ãºltima demo haya salido bien ğŸ¤—"
    bot.reply_to(message, goodbye_message)


@bot.message_handler(commands=['transcribe'])
def handle_transcribe_command(message):
    """
        Handle the 'transcribe' command to initiate audio transcription.

    Args:
        message (Message): The user's command message.

    Returns:
        None
    """
    transcribe_audio_message = "Â¡Perfecto! EnvÃ­ame el audio que deseas transcribir ğŸ”Šâœï¸"
    msg = bot.reply_to(message, transcribe_audio_message)
    bot.register_next_step_handler(msg, handle_audio_transcription)


def handle_audio_transcription(message):
    """
    Transcribe audio and ask for user instructions for processing the transcription.

    Args:
        message: The user's message object containing audio.
    """
    audio_filepath = download_telegram_file(bot, message.audio.file_id)
    transcription = transcribe_audio_with_openai(audio_filepath)
    bot.reply_to(
        message, f"AquÃ­ estÃ¡ tu transcripciÃ³n:\n{transcription}\nÂ¿Quieres hacer algo mÃ¡s con ella? ğŸ§")
    bot.register_next_step_handler(
        message, handle_transcription_instructions, transcription=transcription)


def handle_transcription_instructions(message, transcription):
    """
    Handle user instructions for transcribing and processing text.

    Args:
        message: The user's message object with the instructions.
        transcription (str): The text transcribed to be processed.
    """
    if message.content_type == "voice":
        audio_filepath = download_telegram_file(bot, message.voice.file_id)
        user_instructions = transcribe_audio_with_openai(audio_filepath)
    else:
        user_instructions = message.text
    processed_text = process_text_with_custom_instructions(
        transcription, user_instructions)
    bot.reply_to(message, f"Â¡AquÃ­ lo tienes!ğŸ‘‡: \n{processed_text}")


@bot.message_handler(content_types=["text", "voice"])
def process_openai_step(message: telebot.types.Message):
    """
    Process the message and respond using OpenAI

    Args:
        message (Message): The user's message. It can be an audio (voice) or text message (text)
    Returns:
        None
    """

    if message.content_type == "voice":
        audio_filepath = download_telegram_file(bot, message.voice.file_id)
        message_text = transcribe_audio_with_openai(audio_filepath)
    else:
        message_text = message.text
    try:
        user_id = message.chat.id

        reply_text = conversate(user_id, conversations, message_text, system_prompt=prompts.get(user_id))
        msg = bot.reply_to(message, reply_text)

    except Exception as error:
        bot.reply_to(message, 'Upsi, ha debido de haber algÃºn problema')


bot.enable_save_next_step_handlers(delay=2)
bot.load_next_step_handlers()
bot.infinity_polling()

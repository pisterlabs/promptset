import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.schema import (SystemMessage, HumanMessage, AIMessage)


def main():
    llm = ChatOpenAI(temperature=0)

    st.set_page_config(
        page_title="ChatGPT",
        # page_icon="ğŸ¤—"
    )
    st.header("ChatGPT")

    st.markdown("# &#8203;``ã€å¿™ã—ã„æ–¹å¿…è¦‹ï¼ã€‘``&#8203;\n# ã‚‚ããŸã¦ãƒ†ãƒ¬ãƒ“ã‚’ç°¡å˜ã¾ã¨ã‚")

    # st.image("thum_mogitate.png", width=500)

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = [
            SystemMessage(content="å…¥åŠ›ã•ã‚ŒãŸæ–‡ç« ã‚’300å­—ç¨‹åº¦ã«è¦ç´„ã—ã¦ãã ã•ã„")
        ]

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("ã‚‚ããŸã¦ãƒ†ãƒ¬ãƒ“ã®åŸç¨¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("ChatGPT is typing ..."):
            response = llm(st.session_state.messages)
        st.session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get('messages', [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message('assistant'):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message('user'):
                st.markdown(message.content)
        else:  # isinstance(message, SystemMessage):
            st.write(f"System message: {message.content}")
    
    


if __name__ == '__main__':
    main()

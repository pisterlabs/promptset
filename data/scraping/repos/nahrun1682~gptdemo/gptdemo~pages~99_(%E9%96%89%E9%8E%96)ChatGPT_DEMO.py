import streamlit as st
from langchain.llms import OpenAI
import os
from dotenv import load_dotenv
import openai
#libsãƒ•ã‚©ãƒ«ãƒ€ã®ä¸­ã«ã‚ã‚‹simple_chat_responseã‚’import
from libs.simple_chat_response import *

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))

#ãƒ¯ã‚¤ãƒ‰è¡¨ç¤º
st.set_page_config(layout="wide")

#ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º
st.title('ğŸ¦œChatGPT DEMO')
st.subheader('ã¾ã memoryæ©Ÿèƒ½ã¯æœªå®Ÿè£…' )

model_name = st.radio(label='ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ã­',
                 options=('gpt-3.5-turbo', 'gpt-4'),
                 index=0,
                 horizontal=True,
)
 
# å®šæ•°å®šç¾©
USER_NAME = "user"
ASSISTANT_NAME = "assistant"

# ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜ã—ãŸã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’åˆæœŸåŒ–
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []



user_msg = st.chat_input("ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›")
if user_msg:
    # ä»¥å‰ã®ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’è¡¨ç¤º
    for chat in st.session_state.chat_log:
        with st.chat_message(chat["name"]):
            st.write(chat["msg"])

    # æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    with st.chat_message(USER_NAME):
        st.write(user_msg)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    response = simple_response_chatgpt(model_name,user_msg)
    with st.chat_message(ASSISTANT_NAME):
        assistant_msg = ""
        assistant_response_area = st.empty()
        for chunk in response:
            # å›ç­”ã‚’é€æ¬¡è¡¨ç¤º
            tmp_assistant_msg = chunk["choices"][0]["delta"].get("content", "")
            assistant_msg += tmp_assistant_msg
            assistant_response_area.write(assistant_msg)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’è¿½åŠ 
    st.session_state.chat_log.append({"name": USER_NAME, "msg": user_msg})
    st.session_state.chat_log.append({"name": ASSISTANT_NAME, "msg": assistant_msg})
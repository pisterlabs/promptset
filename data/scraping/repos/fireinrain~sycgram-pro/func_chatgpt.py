import asyncio
import json

import aiohttp
from pyrogram import Client
from pyrogram.types import Message

from core import command
from tools.helpers import Parameters
from pyrogram.enums import ParseMode

from core import bot_config

# import openai

fakeopen_completions_url = 'https://ai.fakeopen.com/v1/chat/completions'


def get_access_token() -> str:
    return bot_config['chatgpt'].get('access_token')


async def fakeopen_completions_chat(query: str, stream_true: bool):
    params = {
        "model": "gpt-3.5-turbo",
        "messages": [
            {
                "role": "user",
                "content": f"{query}"
            }
        ]
        ,
        'stream': stream_true,
    }
    json_data = json.dumps(params)
    headers = {
        'Content-Type': 'application/json',
        'Authorization': 'Bearer ' + get_access_token(),
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) '
                      'Chrome/118.0.0.0 Safari/537.36'
    }
    async with aiohttp.ClientSession() as session:
        async with session.post(fakeopen_completions_url, data=json_data, headers=headers) as response:
            if response.status == 200:
                # ä½¿ç”¨iter_any()æ–¹æ³•é€å—è¯»å–æµå¼æ•°æ®
                result = ""
                async for chunk in response.content.iter_any():
                    # åœ¨è¿™é‡Œå¤„ç†æ¯ä¸ªæ•°æ®å—
                    print(chunk.decode("utf-8"))
                    decoded_chunk = chunk.decode("utf-8")
                    if 'choices' in decoded_chunk and 'delta' in decoded_chunk['choices'][0]:
                        chunk_msg = decoded_chunk['choices'][0]['delta'].get('content', '')
                        result += chunk_msg  # å°†è¾“å‡ºå†…å®¹é™„åŠ åˆ°ç»“æœå­—ç¬¦ä¸²ä¸Š

                        if stream_true:
                            # print(chunk_msg, end='', flush=True)
                            await asyncio.sleep(0.05)
                print(result)
                return result

            else:
                print(f"Failed to fetch data. Status code: {response.status}")
    return ""


# def fakeopen_api(query: str, max: int, stream_true: bool, tem: float):
#     openai.api_base = fakeopen_base
#     openai.api_key = get_access_token()
#     # start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
#
#     response = openai.ChatCompletion.create(
#         model='gpt-3.5-turbo',
#         messages=[
#             {'role': 'user', 'content': query}
#         ],
#         temperature=tem,
#         max_tokens=max,
#         stream=True  # å¼€å¯æµå¼è¾“å‡º
#     )
#
#     result = ""  # åˆ›å»ºä¸€ä¸ªç©ºå­—ç¬¦ä¸²æ¥ä¿å­˜æµå¼è¾“å‡ºçš„ç»“æœ
#
#     for chunk in response:
#         # ç¡®ä¿å­—æ®µå­˜åœ¨
#         if 'choices' in chunk and 'delta' in chunk['choices'][0]:
#             chunk_msg = chunk['choices'][0]['delta'].get('content', '')
#             result += chunk_msg  # å°†è¾“å‡ºå†…å®¹é™„åŠ åˆ°ç»“æœå­—ç¬¦ä¸²ä¸Š
#
#             if stream_true:
#                 # print(chunk_msg, end='', flush=True)
#                 time.sleep(0.05)
#
#     return result  # è¿”å›æµå¼è¾“å‡ºçš„å®Œæ•´ç»“æœ


@Client.on_message(command('chatgpt'))
async def chatgpt(client: Client, message: Message):
    """ä¸chatgptå¯¹è¯"""
    cmd, args = Parameters.get(message)
    query_str = args
    await message.edit_text("ğŸŒæ­£åœ¨è¯¢é—®chatgpt,è¯·ç¨å...")
    full_result = await fakeopen_completions_chat(query_str, True)
    if not full_result:
        full_result = "æ— æ³•è·å–chatgptå›å¤,è¯·æ£€æŸ¥æ’ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ."
    result_text = f"ğŸ” | **ChatGPT** | `å›å¤`\n{full_result}"
    await message.edit_text(
        text=result_text,
        parse_mode=ParseMode.MARKDOWN,
        disable_web_page_preview=True
    )


if __name__ == '__main__':
    asyncio.run(fakeopen_completions_chat("ä½ å¥½", True))

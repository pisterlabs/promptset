import warnings

from real_tools.AskUserTool import AskUserTool
from real_tools.opening_phrase_tool import OpeningPhraseTool
from real_tools.search_flight_ticket_tool import SearchFlightTool
from real_tools.search_hotel_tool import SearchHotelTool
from real_tools.search_sight_ticket_tool import SearchSightTicketTool
from real_tools.search_train_ticket_tool import SearchTrainTool

# Filter out the specific UserWarning from the langchain package
warnings.filterwarnings("ignore", message="You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`")

from langchain.agents import AgentExecutor, ZeroShotAgent
from langchain.callbacks import FinalStreamingStdOutCallbackHandler
from langchain.chains import LLMChain
from langchain.memory import ConversationSummaryBufferMemory
from langchain.prompts import MessagesPlaceholder, PromptTemplate
from langchain.schema import SystemMessage
from langchain.tools import Tool
from langchain.utilities import SerpAPIWrapper
import os



from langchain.llms import OpenAI
from langchain.callbacks import StreamlitCallbackHandler
import streamlit as st

os.environ["OPENAI_API_KEY"] = "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"
os.environ["SERPAPI_API_KEY"] = "886ab329f3d0dda244f3544efeb257cc077d297bb0c666f5c76296d25c0b2279"




############## chainå·¥å…·ä»¬ï¼Œpromptæ˜¯çœŸæ­£å®šä¹‰ä»–ä»¬åŠŸèƒ½çš„åœ°æ–¹ ##############
llm = OpenAI(temperature=0.3)
prompt1 = PromptTemplate(
    input_variables=["content"],
    template="ä»{content}ï¼Œåˆ†æç”¨æˆ·æƒ³å»å“ªä¸ªåŸå¸‚ï¼Œåˆ†æç”¨æˆ·æƒ³å»å“ªä¸ªåŸå¸‚ï¼Œå¿…é¡»è¾“å‡ºä¸€ä¸ªå…·ä½“çš„departure_city(ä¸­æ–‡)å’Œä¸€ä¸ªå…·ä½“çš„arrival_city(ä¸­æ–‡)"
)
prompt2 = PromptTemplate(
    input_variables=["content"],
    template="ä»{content}ï¼Œåˆ†æç”¨æˆ·æƒ³ä»€ä¹ˆæ—¶å€™å»ï¼Œå¿…é¡»è¾“å‡ºä¸€ä¸ª2023-11-24ä»¥åçš„æ—¥æœŸï¼Œè¾“å‡ºæ ¼å¼æ˜¯date:yyyy-MM-dd"
)
prompt4 = PromptTemplate(
    input_variables=["content"],
    template="ä»{content}ï¼Œåˆ†æç”¨æˆ·çš„å–œå¥½ï¼Œç”Ÿæˆæœç´¢çš„ä¸­æ–‡å…³é”®è¯"
)
prompt5 = PromptTemplate(
    input_variables=["content"],
    template="æŠŠ{content}çš„markdownè¡¨æ ¼æ ¼å¼çš„æ—…è¡Œè®¡åˆ’è¡¨æ ¼ï¼Œè¡¥å……å®Œæ•´ï¼Œè®©æœ€ç»ˆçš„æ—…è¡Œè®¡åˆ’è¡¨å˜å¾—åˆç†ä¸”å®Œæ•´ï¼Œåƒä¸€ä½èŒä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆåˆ›ä½œçš„ä¸€æ ·"
)
prompt6 = PromptTemplate(
    input_variables=["content"],
    template="è¿™æ˜¯ä¸€ä¸ªå…œåº•æ–¹æ³•ï¼Œå½“å¯¹è¯å¿…é¡»ç»ˆæ­¢ï¼Œè€Œ{content}ä¸­çš„å†…å®¹ä¸è¶³æˆä¸ºä¸€ä»½æ—…è¡Œè®¡åˆ’æ—¶ï¼Œæ ¹æ®{content}è¡¥å……ç”Ÿæˆä¸€ä»½æ—…è¡Œè®¡åˆ’"
)

search = SerpAPIWrapper()
chain1 = LLMChain(llm=llm, prompt=prompt1)
chain2 = LLMChain(llm=llm, prompt=prompt2)
chain4 = LLMChain(llm=llm, prompt=prompt4)
chain5 = LLMChain(llm=llm, prompt=prompt5)
llm2 = OpenAI(temperature=0.9)
chain6 = LLMChain(llm=llm2, prompt=prompt6)

############## ä¸€ä¸ªç»“åˆäº†è¯­è¨€æ¨¡å‹chainå’Œæœ¬åœ°å‡½æ•°toolçš„toolså·¥å…·åŒ… ##############
tools = [
    Tool(
        name="ç½‘ç»œä¿¡æ¯æœç´¢",
        func=search.run,
        description="useful for when you need to answer questions about current events. You should ask targeted questions",
    ),
    Tool.from_function(
        func=chain1.run,
        name="çƒ­é—¨åŸå¸‚æ¨è",
        description="æ ¹æ®è¾“å…¥çš„ä¿¡æ¯ï¼Œåˆ†æç”¨æˆ·æƒ³å»å“ªä¸ªåŸå¸‚ï¼Œå¿…é¡»è¾“å‡ºdeparture_city(ä¸­æ–‡)ï¼Œ arrival_city(ä¸­æ–‡)",
        # coroutine= ... <- you can specify an async method if desired as well
    ),
    Tool.from_function(
        func=chain2.run,
        name="æ—…è¡Œå‰æ—¥",
        description="æ ¹æ®è¾“å…¥çš„ä¿¡æ¯ï¼Œè·å–ä»Šå¤©çš„æ—¥æœŸä»¥åŠç”¨æˆ·çš„åå¥½ï¼Œåˆ†æä»€ä¹ˆæ—¶é—´å¯èƒ½é€‚åˆç”¨æˆ·ï¼Œå¿…é¡»è¾“å‡ºä¸€ä¸ªä»Šå¤©ä»¥åçš„æ—¥æœŸï¼Œè¾“å‡ºæ ¼å¼æ˜¯yyyy-MM-dd",
        # coroutine= ... <- you can specify an async method if desired as well
    ),
    Tool.from_function(
        func=chain4.run,
        name="ç”¨æˆ·ç”»åƒ",
        description="æ ¹æ®è¾“å…¥çš„ä¿¡æ¯ï¼Œåˆ†æç”¨æˆ·çš„å–œå¥½ï¼Œç”Ÿæˆæœç´¢çš„ä¸­æ–‡å…³é”®è¯",
        # coroutine= ... <- you can specify an async method if desired as well
    ),
    # Tool.from_function(
    #     func=chain5.run,
    #     name="å®Œå–„ä¿¡æ¯",
    #     description="åœ¨æŠŠfinal_answeräº¤ç»™ç”¨æˆ·ä¹‹å‰éœ€è¦ç”¨`complete_table`å·¥å…·è¡¥å……ç©ºç™½çš„åœ°æ–¹ï¼Œè®©æœ€ç»ˆçš„æ—…è¡Œè®¡åˆ’è¡¨å˜å¾—åˆç†ä¸”å®Œæ•´ï¼Œåƒä¸€ä½èŒä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆåˆ›ä½œçš„ä¸€æ ·ï¼Œæ³¨æ„æ¯æ™šåº”è¯¥ä½åœ¨ä¸åŒçš„é…’åº—",
    #     # coroutine= ... <- you can specify an async method if desired as well
    # ),
    Tool.from_function(
        func=chain6.run,
        name="å…œåº•æ–¹æ³•",
        description="è¿™æ˜¯ä¸€ä¸ªå…œåº•æ–¹æ³•ï¼Œå½“å¯¹è¯å¿…é¡»ç»ˆæ­¢ï¼Œä½†è¿˜æ²¡äº§ç”Ÿfinal answerçš„æ—¶å€™ä½œä¸ºé™çº§æ–¹æ¡ˆ",
        # coroutine= ... <- you can specify an async method if desired as well
    ),
    SearchFlightTool(),
    SearchHotelTool(),
    SearchSightTicketTool(),
    SearchTrainTool(),
    OpeningPhraseTool(),
    AskUserTool(),
]

############## å†³ç­–agentï¼Œtoolsåªæ˜¯åå­— ##############
prefix = """
            
            ä¸€åˆ‡å¼€å§‹å‰ï¼Œå…ˆå’Œç”¨æˆ·è¯´ä¸ªå¼€åœºç™½
            Answer the following questions as best you can. You have access to the following tools:
            æœ€ç»ˆç›®æ ‡æ˜¯ç”Ÿæˆä¸€ä»½æ‹¥æœ‰å‡ºå‘å’Œå›æ¥æ—¶é—´ã€äº¤é€šæ–¹å¼ï¼Œæ¯å¤©æ¸¸ç©æ™¯ç‚¹ï¼Œæ¯æ™šä½çš„é…’åº—çš„æ—…è¡Œæ–¹æ¡ˆ,å¹¶ç”¨`write_file`å·¥å…·æŠŠç»“æœå†™å…¥åˆ°æœ¬åœ°æ–‡ä»¶ä¸­"""
suffix = """
    ä¸‹é¢æ˜¯å·¥å…·çš„ä»‹ç»
        `opening_phrase`æ˜¯ä½ çš„å¼€åœºç™½
        `çµæ„ŸæŒ–æ˜`å¯ä»¥å‘ç”¨æˆ·å‘èµ·æé—®ï¼Œæ ¹æ®ç”¨æˆ·çš„å›ç­”è¿›ä¸€æ­¥åšå…¶ä»–æ¨ç†ï¼Œå¦‚æœç”¨æˆ·å®åœ¨æ²¡æœ‰æä¾›æœ‰æ•ˆç­”æ¡ˆï¼Œå¯ä»¥ç”¨`çƒ­é—¨åŸå¸‚æ¨è``æ—…è¡Œå‰æ—¥`è¡¥å…¨ä¿¡æ¯ï¼Œä½†æ˜¯æ³¨æ„è¯¢é—®ç”¨æˆ·çš„æ¬¡æ•°ä¸èƒ½è¶…è¿‡å››æ¬¡
        `ç”¨æˆ·ç”»åƒ`å¯ä»¥åˆ†æç”¨æˆ·çš„å–œå¥½ï¼Œæ‹¿åˆ°æœç´¢æ¡ä»¶keywordï¼Œ
        `Qunaræœºç¥¨æœç´¢`çš„å‚æ•°æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²â€œdeparture_city + arrival_city + dateâ€ä¸­é—´ç”¨â€œ+â€åˆ†å‰²ï¼Œ
        `Qunaræ™¯ç‚¹æœç´¢`çš„å‚æ•°ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ˜¯arrival_city
        `Qunaré…’åº—æœç´¢` çš„å‚æ•°æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²â€œcity + check_in_data + leave_date+ keywordâ€ï¼Œä¸­é—´ç”¨â€œ+â€åˆ†å‰²
        `Qunarç«è½¦ç¥¨æœç´¢`çš„å‚æ•°æ˜¯ä¸€ä¸ªå­—ç¬¦â€œdeparture_city+  arrival_city+ dateâ€ï¼Œä¸­é—´ç”¨â€œ+â€åˆ†å‰²
        ä½ éœ€è¦ç¡®å®š1.ç”¨æˆ·å‡†å¤‡ä»å“ªé‡Œå‡ºå‘ï¼Œå»å“ªé‡Œç©
                2.ç”¨æˆ·ä»€ä¹ˆæ—¶é—´å»æ—…æ¸¸ï¼Œå‡†å¤‡ç©å„¿å‡ å¤©
                3.ç”¨æˆ·å‡†å¤‡ç”¨ä»€ä¹ˆæ–¹å¼å»ç›®æ ‡åœ°ï¼Œä»€ä¹ˆæ–¹å¼å›æ¥
                4.ç”¨æˆ·æ¯å¤©è¦ç©å“ªäº›æ™¯ç‚¹
                5.åŸºäºè¿™äº›æ™¯ç‚¹ï¼Œæ¯æ™šåº”è¯¥ä½åœ¨å“ªé‡Œï¼Œæ¯å¤©ä½çš„åœ°æ–¹åº”è¯¥ä¸ä¸€æ ·
        Begin! ç”¨markdownæ ¼å¼çš„è¡¨æ ¼å±•ç¤ºä½ ç”Ÿæˆçš„æ–¹æ¡ˆï¼Œå†…å®¹æ˜¯ä¸­æ–‡ï¼ŒRemember to speak as a pirate when ç”¨markdownæ ¼å¼çš„è¡¨æ ¼å±•ç¤ºä½ ç”Ÿæˆçš„æ–¹æ¡ˆï¼Œå†…å®¹æ˜¯ä¸­æ–‡çš„markdownè¡¨æ ¼
       ç±»ä¼¼ä¸‹é¢è¿™æ ·ï¼Œè¦ç´ ä¸€å®šè¦é½å…¨
        | æ—¥æœŸ   | å‡ºå‘/å›ç¨‹ | äº¤é€šæ–¹å¼        | ä»·æ ¼   | ç›®çš„åœ° | ä¸»è¦æ´»åŠ¨      | ä½å®¿        | é…’åº—ä»·æ ¼   |
        |------|-------|-------------|------|-----|-----------|-----------|--------|
        | 7æœˆ1æ—¥ | å‡ºå‘    | é£æœºï¼ˆçº½çº¦ - å·´é»ï¼‰ | $500 | å·´é»  | æŠµè¾¾ã€ä¼‘æ¯     | è¯ºå¯Œç‰¹å·´é»ä¸­å¿ƒé…’åº— | $150/æ™š |
        | 7æœˆ2æ—¥ | -     | -           | -    | å·´é»  | å¢æµ®å®«å‚è§‚     | è¯ºå¯Œç‰¹å·´é»ä¸­å¿ƒé…’åº— | $150/æ™š |
        | 7æœˆ3æ—¥ | -     | -           | -    | å·´é»  | å¡çº³æ²³æ¸¸èˆ¹     | è¯ºå¯Œç‰¹å·´é»ä¸­å¿ƒé…’åº— | $150/æ™š |
        | 7æœˆ4æ—¥ | -     | -           | -    | å·´é»  | å·´é»åœ£æ¯é™¢ã€æ‹‰ä¸åŒº | è¯ºå¯Œç‰¹å·´é»ä¸­å¿ƒé…’åº— | $150/æ™š |
        | 7æœˆ5æ—¥ | -     | -           | -    | å·´é»  | å‡¡å°”èµ›å®«ä¸€æ—¥æ¸¸   | è¯ºå¯Œç‰¹å·´é»ä¸­å¿ƒé…’åº— | $150/æ™š |
        | 7æœˆ6æ—¥ | -     | -           | -    | å·´é»  | å·´é»è¿ªå£«å°¼ä¹å›­   | è¯ºå¯Œç‰¹å·´é»ä¸­å¿ƒé…’åº— | $150/æ™š |
        . Use lots of "Args"
    ï¼Œè®©æœ€ç»ˆçš„æ—…è¡Œè®¡åˆ’è¡¨å˜å¾—åˆç†ä¸”å®Œæ•´ï¼Œåƒä¸€ä½èŒä¸šçš„æ—…è¡Œè§„åˆ’å¸ˆåˆ›ä½œçš„ä¸€æ ·
        
Question: {input}

History Memory: {memory}
{agent_scratchpad}"""
prompt = ZeroShotAgent.create_prompt(
    tools, prefix=prefix, suffix=suffix, input_variables=["input", "agent_scratchpad"]
)
tool_names = [tool.name for tool in tools]
llm_chain = LLMChain(llm=OpenAI(temperature=0,model_name="gpt-4-1106-preview") #gpt-3.5-turbo-1106 gpt-4-1106-preview
                     , prompt=prompt)
agent = ZeroShotAgent(llm_chain=llm_chain, allowed_tools=tool_names)




############## çœŸæ­£çš„å¸¦äº†ï¼ˆå¤§è„‘agentï¼‰çš„æ‰§è¡Œagent ##############
system_message = SystemMessage(
    # ï¼ï¼ï¼ è¿™ä¸ªsystem messageä¼¼ä¹å¯¹ç»“æœæ²¡å½±å“
    content=""
    # """ä½ æ˜¯ä¸€ä¸ªæ—…è¡Œæœç´¢å°åŠ©æ‰‹ï¼Œä½ éœ€è¦
    #     1ã€ ç”¨ â€guess_cityâ€œ å’Œ â€guess_dateâ€œ  å·¥å…·çŒœåˆ° ç”¨æˆ·æƒ³å»çš„åœ°æ–¹å’Œæ—¶é—´ ,
    #     2. æ ¹æ®1ä¸­ç”Ÿæˆçš„ä¿¡æ¯äº§ç”Ÿdeparture_cityï¼Œ arrival_cityï¼Œ dateè¿™ä¸‰ä¸ªå‚æ•°ï¼Œç„¶åè°ƒç”¨`search_flight`ï¼Œè¿”å›ç»™ç”¨æˆ·æœç´¢ç»“æœ
    #     3. æ ¹æ®1ä¸­ç”Ÿæˆçš„ä¿¡æ¯arrival_cityï¼Œå»æœç´¢ç›®æ ‡åŸå¸‚çš„æ™¯ç‚¹
    #     4. æŸ¥æ‰¾æ™¯ç‚¹é™„è¿‘çš„é…’åº—
    #     4. æŠŠ2.3çš„ç»“æœç»„ç»‡æˆä¸€ä»½æ—…æ¸¸è§„åˆ’ï¼Œè¿”å›ç»™ç”¨æˆ·
    #     6/ è¯·ä½¿ç”¨ä¸­æ–‡å›å¤."""
)
memory = ConversationSummaryBufferMemory(
    memory_key="memory", return_messages=True, llm=llm, max_token_limit=300)

agent_kwargs = {
    "extra_prompt_messages": [MessagesPlaceholder(variable_name="memory")],
    "system_message": system_message,
}
llm = LLMChain(
    llm=OpenAI(temperature=0
               ,model_name="gpt-4-1106-preview"
               ,streaming=True
               ,callbacks=[FinalStreamingStdOutCallbackHandler(answer_prefix_tokens=["The", "plan", ":"])],)
    , prompt=prompt1)

agent_executor = AgentExecutor.from_agent_and_tools(
    agent=agent,
    tools=tools,
    verbose=True,
    handle_parsing_errors = "Check your output and make sure it conforms!", # å¹¶ä¸èƒ½ç”Ÿæ•ˆï¼Œå»å¤„ç†é”™è¯¯
    agent_kwargs = agent_kwargs,  # è®¾å®š agent è§’è‰²
    memory = memory,  # é…ç½®è®°å¿†æ¨¡å¼
    #llm=llm,
    max_iterations=10, # ï¼ï¼ï¼æ§åˆ¶actionçš„æœ€å¤§è½®æ•°
    early_stopping_method="generate", # !!!å…œåº•ç­–ç•¥ï¼Œè¶…è¿‡æœ€å¤§è½®æ•°ä¸ä¼šæˆ›ç„¶è€Œæ­¢ï¼Œä¼šæœ€åè°ƒç”¨ä¸€æ¬¡æ–¹æ³•,ä½†æ˜¯ç›®å‰ä¼¼ä¹è¿˜æ²¡åŠæ³•ç²¾å‡†æ§åˆ¶è°ƒç”¨å“ªä¸ª
)




if __name__ == '__main__':

    st.title("ğŸ” Qunar VIVA")
    if prompt := st.chat_input():
        st.chat_message("user").write(prompt)
        with st.chat_message("assistant"):
            st_callback = StreamlitCallbackHandler(st.container())
            response = agent_executor.run(prompt, callbacks=[st_callback])
            st.write(response)
